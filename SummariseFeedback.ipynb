{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback insights demo with Azure OpenAI GPT\n",
    "Use GPT to summarise and extract insights from customer feedback\n",
    "\n",
    "## 0. Pre-reqs\n",
    "- Python 3.10.12 was used to create this\n",
    "- Access to pip install stuff\n",
    "    - openai\n",
    "    - pandas\n",
    "    - tiktoken (for counting the number of tokens in text)\n",
    "    - dotenv (for storing keys in .env file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install openai\n",
    "%pip install pandas\n",
    "%pip install tiktoken\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data and explore a bit\n",
    "For the purposes of this demo the data is in CSV file and we'll import it using Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('CustomerFeedback.csv')\n",
    "\n",
    "# What's in there?\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Explore Summarisation\n",
    "### Environment setup\n",
    "You'll need to create a file called `.env` that contains the following:\n",
    "```\n",
    "AZURE_OPENAI_SERVICE = \"<name of AOAI service in portal\"\n",
    "AZURE_OPENAI_KEY = \"<API Key for AOAI service>\"\n",
    "AZURE_OPENAI_MODEL = \"<e.g. gpt-35-turbo>\"\n",
    "AZURE_OPENAI_DEPLOYMENT = \"<deployment name in AI studio>\"\n",
    "```\n",
    "\n",
    "### Setup Azure OpenAI service\n",
    "And some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Load config from .env file (instructions above)\n",
    "load_dotenv()\n",
    "AZURE_OPENAI_SERVICE = os.getenv('AZURE_OPENAI_SERVICE')\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv('AZURE_OPENAI_DEPLOYMENT')\n",
    "AZURE_OPENAI_MODEL = os.getenv('AZURE_OPENAI_MODEL')\n",
    "AZURE_OPENAI_KEY = os.getenv('AZURE_OPENAI_KEY')\n",
    "\n",
    "# Configure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = AZURE_OPENAI_KEY\n",
    "\n",
    "# Helper function to call OpenAI\n",
    "def call_gpt(messages: str) -> str:\n",
    "    response = openai.ChatCompletion.create(\n",
    "                    deployment_id=AZURE_OPENAI_DEPLOYMENT,\n",
    "                    model=AZURE_OPENAI_MODEL,\n",
    "                    messages=messages, \n",
    "                    temperature=0.7,   # WARNING: setting to < 0.7 can cause infinite loops\n",
    "                    stream=False\n",
    "                    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Helper function to make the messages in the required ChatCompletion format\n",
    "def make_messages(system_prompt: str, user_prompt: str) -> str:\n",
    "    messages = []\n",
    "    messages.append({\"role\" : \"system\", \"content\" : system_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_prompt })\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test summarising a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_record_summarisation_prompt = \"\"\"\n",
    "The [comment] below is a user review of Better Bank services and represents their recent experience with these services. You should answer the questions below based solely on the content of [comment] and no further content should be generated.  \n",
    " \n",
    "[FACTS]:  \n",
    "Use the following facts to help you answer the questions:  \n",
    "- Better Bank is in the banking and insurance industry.\n",
    "- They offer products including Home Loans, Personal Loans, Credit Cards, Savings Accounts, Term Deposits and Insurance.\n",
    "- Their competitors include Bank A, Bank B or Insurance Co A\n",
    " \n",
    "[OUTPUT]:\n",
    "Each question from [QUESTIONS] below is in the format \"json-element-name::question\".   \n",
    "Format your answers as a single JSON document using the json-element-name of each question.  \n",
    " \n",
    "[QUESTIONS]  \n",
    "1. summary::Generate a summary of the [comment] in less than 50 words.  \n",
    "2. competitors::Any Better Bank competitors. Answer [N/A] if there are no mentions.  \n",
    "3. products::Any Better Bank products mentioned. Answer [N/A] if there are no mentions.\n",
    "4. classifications::Classify the [comment] into one of the following categories:   \n",
    "    - Wait time  \n",
    "    - Price  \n",
    "    - Rates  \n",
    "    - Customer Service  \n",
    "    - Premiums \n",
    "    - Online platform   \n",
    "    - Other   \n",
    "\n",
    "[comment] \"\"\"\n",
    "\n",
    "print(\"==== SYSTEM PROMPT:\\n\" + single_record_summarisation_prompt)\n",
    "comment = 'COMMENT:' + df.iloc[0][\"Comment\"]\n",
    "print(\"==== COMMENT\\n\" + comment)\n",
    "\n",
    "# call GPT to summarise using the prompt\n",
    "response = call_gpt(make_messages(single_record_summarisation_prompt, comment))\n",
    "print(\"\\n===== RESPONSE:\\n\" + response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Process the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supporting modules \n",
    "import os\n",
    "import json\n",
    "\n",
    "# Create output folder if required\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Single Record summarisation and output to file\n",
    "\n",
    "This will create a file in the `output` folder.  \n",
    "The file will create **even if one (or all) records fail** JSON conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print total survey comments in dataframe\n",
    "print(len(df), ' total feedback items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Make sure you \"Execute Above Cells\" using the pop-up menu at the top right of this code block\n",
    "\n",
    "# LIMIT THIS RUN TO N RECORDS\n",
    "max_records_to_process = 100\n",
    "df_single_records = df.head(max_records_to_process).copy()\n",
    "\n",
    "# Error log - define a DF for capturing any summarisation errors (e.g. content filtering)\n",
    "df_errors = pd.DataFrame(columns=['CommentID', 'Date', 'ERROR'])\n",
    "\n",
    "\n",
    "single_record_summarisation_prompt = \"\"\"\n",
    "The [comment] below is a user review of Better Bank services and represents their recent experience with these services. You should answer the questions below based solely on the content of [comment] and no further content should be generated.  \n",
    " \n",
    "[FACTS]:  \n",
    "Use the following facts to help you answer the questions:  \n",
    "- Better Bank is in the banking and insurance industry.\n",
    "- They offer products including Home Loans, Personal Loans, Credit Cards, Savings Accounts, Term Deposits and Insurance.\n",
    "- Their competitors include Bank A, Bank B or Insurance Co A\n",
    " \n",
    "\n",
    "Review the feedback [COMMENT] below, and summarise it, into a JSON schema as below:\n",
    "\n",
    "{\n",
    "    \"Summary\": <Generate a summary of the [comment] in less than 50 words>,\n",
    "    \"Competitor\": <The first Better Bank competitor mentioned. Answer [N/A] if there are no mentions.>,\n",
    "    \"Products\": <The main Better Bank product mentioned. Answer [N/A] if there are no mentions.>,\n",
    "    \"Classification\": <Classify the [comment] into a single category: Wait time, Price, Rates, Customer Service, Premiums, Online platform, Other>\n",
    "}\n",
    "\n",
    "Double-check that the JSON schema is valid JSON.\n",
    "\n",
    "The [COMMENT] is:\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n=== Processing first\", len(df_single_records), \"single records >>>\\n\")\n",
    "\n",
    "for index, row in df_single_records.iterrows():\n",
    "    try:\n",
    "        print(f\"Summarising Survey record: {row['CommentID']}\")\n",
    "        df_single_records.at[index, 'JSON'] = call_gpt(make_messages(single_record_summarisation_prompt, ' COMMENT:' + row['Comment']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarising Survey record: {row['CommentID']}. Error: {e}\")\n",
    "\n",
    "        # remove the record from further processing\n",
    "        df_single_records.drop(index, inplace=True)\n",
    "\n",
    "        # copy the details into df_errors\n",
    "        new_row = {'CommentID': row['CommentID'], 'ERROR': e}\n",
    "        df_errors = pd.concat([df_errors, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
    "\n",
    "# if we got errors\n",
    "if len(df_errors) > 0:\n",
    "    FILENAME_ERRORS_SINGLE='output/errors_summary_single_records.csv'\n",
    "    df_errors.to_csv(FILENAME_ERRORS_SINGLE, index=False)\n",
    "    print('\\n==== Wrote ERROR file:', FILENAME_ERRORS_SINGLE, '\\n')\n",
    "\n",
    "\n",
    "# For each row in the DF, check the JSON column contains valid JSON, and add each of the JSON keys as a new column\n",
    "for index, row in df_single_records.iterrows():\n",
    "    try:\n",
    "        json_data = json.loads(row['JSON'])\n",
    "        for key in json_data.keys():\n",
    "            df_single_records.loc[index, key] = json_data[key]\n",
    "        print(f\"Converted JSON for Feedback comment: {row['CommentID']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e} processing JSON for Survey comment: {row['CommentID']}:\")\n",
    "        print(row['JSON'])\n",
    "        \n",
    "        # Log the errors to a file  \n",
    "        df_single_records.to_csv(FILENAME_ERRORS_SINGLE, index=False)\n",
    "        print('\\n==== Wrote file: ' + FILENAME_ERRORS_SINGLE)\n",
    "        \n",
    "        # We shouldn't fail the whole file because GPT mis-formatted one or more records\n",
    "        continue\n",
    "\n",
    "df_single_records.head(10)\n",
    "\n",
    "## Drop the JSON column\n",
    "df_single_records.drop(columns=['JSON'], inplace=True)\n",
    "\n",
    "# write the selected_rows DF to a CSV file\n",
    "FILENAME_SINGLE='output/AOAI-FeedbackSummary.csv'\n",
    "df_single_records.to_csv(FILENAME_SINGLE, index=False)\n",
    "print('\\n==== Wrote file: ' + FILENAME_SINGLE)\n",
    "print(\"==== THIS DOESN'T mean that all JSON was successful please check for ERRORS above ====\")\n",
    "print(\"(ignore any 'FutureWarning' messages)\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
